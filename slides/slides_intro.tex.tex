\documentclass[11pt,handout,aspectratio=169]{beamer}


\input{./defs.tex}

\title[STA437-Week1]{STA 437/2005: \\ Methods for Multivariate Data}
\subtitle[]{Week 1: Introduction and Preliminaries}
\author[Prob Learning]{Piotr Zwiernik}
\institute[UofT]{University of Toronto}
\date{}


\usepackage{Sweave}


\begin{document}

\maketitle

\begin{frame}{Table of contents}
  \setbeamertemplate{section in toc}[sections numbered]
  \tableofcontents%[hideallsubsections]
\end{frame}



\section{Introduction to Gaussian Processes (GPs)}

\begin{frame}{What are Gaussian Processes?}
\begin{itemize}
    \item A \textbf{Gaussian Process (GP)} is a generalization of the multivariate normal distribution to a collection of random variables indexed by a set \( T \).
    \item A GP defines a distribution over functions, characterized by:
    \begin{itemize}
        \item A \textbf{mean function}: \( m(t) = \mathbb{E}[X_t] \)
        \item A \textbf{kernel function}: \( k(t, t') = \text{Cov}(X_t, X_{t'}) \)
    \end{itemize}
    \item For any finite set of points \( \{t_1, \dots, t_n\} \subset T \), the corresponding vector \( (X_{t_1}, \dots, X_{t_n}) \) follows a multivariate normal distribution.
\end{itemize}
\end{frame}


\begin{frame}{Key Properties of GPs}
\begin{itemize}
    \item \textbf{Mean Function:} Specifies the average behavior of the process:
    \[
    m(t) = \mathbb{E}[X_t].
    \]
    \item \textbf{Kernel Function:} Defines the covariance structure:
    \[
    k(t, t') = \text{Cov}(X_t, X_{t'}).
    \]
    \item \textbf{Positive Semi-Definiteness:} For any finite set \( \{t_1, \dots, t_n\} \), the covariance matrix \( \Sigma \) with entries \( \Sigma_{ij} = k(t_i, t_j) \) is positive semi-definite.
\end{itemize}
\end{frame}

\begin{frame}{Common Kernels in GPs}
\begin{itemize}
    \item \textbf{Squared Exponential (RBF) Kernel:}
    \[
    k_{\textsc{e}}(t, t') = \sigma^2 \exp\left(-\frac{\|t - t'\|^2}{2\ell^2}\right).
    \]
    \begin{itemize}
        \item Controls smoothness of the functions sampled from the GP.
        \item Length scale \( \ell \): Correlation distance.
        \item Signal variance \( \sigma^2 \): Scale of the output.
    \end{itemize}
    \item \textbf{Mat\'{e}rn Kernel:}
    \[
    k_{\textsc{m}}(t, t') = \sigma^2 \frac{2^{1-\nu}}{\Gamma(\nu)} \left(\sqrt{2\nu} \frac{\|t - t'\|}{\ell}\right)^\nu K_\nu\left(\sqrt{2\nu} \frac{\|t - t'\|}{\ell}\right).
    \]
    \begin{itemize}
        \item \( \nu \): Smoothness parameter.
        \item More flexible than the RBF kernel for modeling rough functions.
    \end{itemize}
\end{itemize}
\end{frame}

\section{Gaussian Processes for Spatial Data}

\begin{frame}{Example: Modeling Spatial Data with GPs}
\begin{itemize}
    \item Gaussian Processes are widely used in spatial statistics to model correlated observations over geographic regions.
    \item Example: Modeling temperature across a grid of locations.
\end{itemize}

%\begin{minted}[frame=single,fontsize=\small]{r}
%# Generate spatially correlated data
%set.seed(42)
%n <- 100
%locs <- expand.grid(x = seq(0, 1, length.out = n), y = seq(0, 1, length.out = n))
%true_cov <- exp(-rdist(locs) / 2)  # Exponential kernel
%temp <- t(chol(true_cov)) %*% rnorm(n * n)
%image(matrix(temp, n, n), main = "Simulated Temperature Data")
%\end{minted}
\end{frame}

\begin{frame}{Spatial GP: Prediction}
\begin{enumerate}
    \item Combine training and test locations.
    \item Compute the covariance matrix using the kernel function.
    \item Use Gaussian conditioning formulas:
    \begin{align*}
        \mathbb{E}[\mathbf{y}_\text{test} | \mathbf{y}_\text{train}] &= \mathbf{k}_\text{test,train}^\top \mathbf{K}_\text{train,train}^{-1} \mathbf{y}_\text{train}, \\
        \text{Cov}(\mathbf{y}_\text{test} | \mathbf{y}_\text{train}) &= \mathbf{K}_\text{test,test} - \mathbf{k}_\text{test,train}^\top \mathbf{K}_\text{train,train}^{-1} \mathbf{k}_\text{test,train}.
    \end{align*}
\end{enumerate}
\end{frame}

\section{Nonparametric Regression with GPs}

\begin{frame}{Nonparametric Regression}
\begin{itemize}
    \item GPs can be used for nonparametric regression:
    \[
    y_i = f(x_i) + \epsilon, \quad \epsilon \sim \mathcal{N}(0, \sigma^2).
    \]
    \item Prior over \( f(x) \): GP defined by \( m(x) \) and \( k(x, x') \).
    \item Prediction involves computing the posterior GP.
\end{itemize}
\end{frame}

%\begin{frame}{Code Example: Nonparametric Regression}
%\begin{minted}[frame=single,fontsize=\small]{r}
%# Generate training data
%x_train <- seq(0, 10, length.out = 10)
%y_train <- sin(x_train) + rnorm(length(x_train), sd = 0.1)
%
%# Test points
%x_test <- seq(0, 10, length.out = 100)
%
%# RBF kernel
%k <- function(x, x_prime, length_scale = 1) {
%    exp(-0.5 * (outer(x, x_prime, "-")^2) / length_scale^2)
%}
%
%# Covariance matrices
%K <- k(x_train, x_train)
%K_s <- k(x_train, x_test)
%K_ss <- k(x_test, x_test)
%
%# Posterior mean and covariance
%mu_s <- t(K_s) %*% solve(K) %*% y_train
%\end{minted}
%\end{frame}

\begin{frame}{Summary}
\begin{itemize}
    \item Gaussian Processes are a versatile tool for regression and spatial modeling.
    \item Key components:
    \begin{itemize}
        \item Mean function.
        \item Kernel function.
    \end{itemize}
    \item Next: Applications of GPs in high-dimensional data.
\end{itemize}
\end{frame}

\end{document}
